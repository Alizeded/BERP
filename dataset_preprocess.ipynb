{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast  # noqa: E402\n",
    "import os  # noqa: E402\n",
    "import random  # noqa: E402\n",
    "from concurrent.futures import ThreadPoolExecutor  # noqa: E402\n",
    "from pathlib import Path  # noqa: E402\n",
    "\n",
    "import matplotlib.pyplot as plt  # noqa: E402\n",
    "import pandas as pd  # noqa: E402\n",
    "import seaborn as sns  # noqa: E402\n",
    "import sklearn.model_selection as ms  # noqa: E402\n",
    "import torch  # noqa: E402\n",
    "import torchaudio  # noqa: E402\n",
    "\n",
    "from src.preprocessing import RIRutils as iru\n",
    "from src.utils.unitary_linear_norm import unitary_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed fix\n",
    "torch.manual_seed(2036)\n",
    "random.seed(2036)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- prepare the noise -------------------\n",
    "# DEMAND\n",
    "savepath = \"./data/noise_dataset\"\n",
    "DEMANDnoise_path = \"~/Data/Datasets/DEMAND_noise\"\n",
    "iru.readNoise_DEMAND(DEMANDnoise_path, savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./data/noise_dataset\"\n",
    "BUT_path = \"~/Data/Datasets/BUT_ReverbDB\"\n",
    "iru.readNoise_BUT(BUT_path, savepath, csv_savemode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- read the noise -------------------\n",
    "noisepath_label = \"./data/noise_dataset/noise.metadata/noise_label.csv\"\n",
    "noise_label = pd.read_csv(noisepath_label)\n",
    "noisepath_data = \"./data/noise_dataset/noise.data\"\n",
    "noise_database = []\n",
    "for i in range(0, len(noise_label[\"filename\"])):\n",
    "    noise, fs = torchaudio.load(\n",
    "        os.path.join(noisepath_data, noise_label[\"filename\"][i])\n",
    "    )\n",
    "    noise_database.append(noise)\n",
    "# shuffle the noise\n",
    "random.shuffle(noise_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arni RIR dataset\n",
    "torch.set_default_dtype(torch.float64)\n",
    "Arni_path = \"~/Data/Datasets/Arni_RIR_dataset\"\n",
    "savepath = \"./data/RIR_aggregated\"\n",
    "iru.readRIR_Arni(Arni_path, savepath, csv_savemode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motus RIR dataset\n",
    "Motus_path = \"~/Data/Datasets/Motus_RIR\"\n",
    "savepath = \"./data/RIR_aggregated\"\n",
    "iru.readRIR_Motus(Motus_path, savepath, csv_savemode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT RIR dataset\n",
    "BUT_path = \"~/Data/Datasets/BUT_ReverbDB\"\n",
    "savepath = \"./data/RIR_aggregated\"\n",
    "iru.readRIR_BUT(BUT_path, savepath, csv_savemode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACE RIR dataset\n",
    "ACE_path = \"~/Data/Datasets/ACE_RIR\"\n",
    "savepath = \"./data/RIR_aggregated\"\n",
    "iru.readRIR_ACE(ACE_path, savepath, csv_savemode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_path = \"~/Data/Datasets/OpenAIR\"\n",
    "root_path = \"./data/RIR_aggregated\"\n",
    "savepath = \"./data/RIR_aggregated\"\n",
    "iru.readRIR_OpenAIR(common_path, root_path, savepath, csv_savemode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_manifest_path = \"./data/RIR_aggregated/RIR.metadata/ThTtDistRcvOriSrc_label.csv\"\n",
    "rir_manifest = pd.read_csv(rir_manifest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For first data balancing, we use equal numbers of every room to investigate the volume distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance the RIR dataset for equal numbers of rm ID (per 800)\n",
    "import random\n",
    "\n",
    "rir_manifest_ID_sum = pd.DataFrame(\n",
    "    columns=[\"RIR\", \"roomID\", \"Th\", \"Tt\", \"volume\", \"distRcv\", \"oriSrc\"]\n",
    ")\n",
    "\n",
    "for id in range(1, 40):\n",
    "    rir_manifest_id = rir_manifest[rir_manifest[\"roomID\"] == \"rmID_\" + str(id)].iloc[\n",
    "        0:1\n",
    "    ]\n",
    "    rir_manifest_ID_sum = pd.concat(\n",
    "        [rir_manifest_ID_sum, rir_manifest_id], ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>roomID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>rmID_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>rmID_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>rmID_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>rmID_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.0</td>\n",
       "      <td>rmID_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63.0</td>\n",
       "      <td>rmID_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73.0</td>\n",
       "      <td>rmID_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>98.0</td>\n",
       "      <td>rmID_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.0</td>\n",
       "      <td>rmID_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101.0</td>\n",
       "      <td>rmID_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>103.0</td>\n",
       "      <td>rmID_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>107.0</td>\n",
       "      <td>rmID_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>194.0</td>\n",
       "      <td>rmID_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>194.0</td>\n",
       "      <td>rmID_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>202.0</td>\n",
       "      <td>rmID_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>231.0</td>\n",
       "      <td>rmID_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>244.0</td>\n",
       "      <td>rmID_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>367.0</td>\n",
       "      <td>rmID_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>908.0</td>\n",
       "      <td>rmID_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1033.0</td>\n",
       "      <td>rmID_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>rmID_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1140.0</td>\n",
       "      <td>rmID_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>rmID_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1560.0</td>\n",
       "      <td>rmID_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>rmID_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2399.0</td>\n",
       "      <td>rmID_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2600.0</td>\n",
       "      <td>rmID_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2706.0</td>\n",
       "      <td>rmID_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>rmID_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>rmID_35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>rmID_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>rmID_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>rmID_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>rmID_33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>rmID_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>rmID_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15700.0</td>\n",
       "      <td>rmID_36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>rmID_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>47000.0</td>\n",
       "      <td>rmID_32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     volume   roomID\n",
       "0      32.0   rmID_4\n",
       "1      35.0  rmID_22\n",
       "2      40.0  rmID_38\n",
       "3      46.0  rmID_17\n",
       "4      49.0  rmID_18\n",
       "5      63.0   rmID_2\n",
       "6      73.0  rmID_12\n",
       "7      98.0   rmID_8\n",
       "8     100.0  rmID_37\n",
       "9     101.0  rmID_15\n",
       "10    103.0   rmID_5\n",
       "11    107.0   rmID_9\n",
       "12    194.0  rmID_11\n",
       "13    194.0  rmID_13\n",
       "14    202.0   rmID_1\n",
       "15    231.0  rmID_10\n",
       "16    244.0  rmID_16\n",
       "17    367.0  rmID_14\n",
       "18    908.0  rmID_21\n",
       "19   1033.0   rmID_3\n",
       "20   1100.0   rmID_7\n",
       "21   1140.0  rmID_39\n",
       "22   1500.0  rmID_31\n",
       "23   1560.0  rmID_19\n",
       "24   2000.0  rmID_23\n",
       "25   2399.0  rmID_26\n",
       "26   2600.0  rmID_29\n",
       "27   2706.0   rmID_6\n",
       "28   3500.0  rmID_24\n",
       "29   3500.0  rmID_35\n",
       "30   3600.0  rmID_30\n",
       "31   4500.0  rmID_34\n",
       "32   6000.0  rmID_28\n",
       "33   8000.0  rmID_33\n",
       "34   8000.0  rmID_20\n",
       "35   9000.0  rmID_27\n",
       "36  15700.0  rmID_36\n",
       "37  18000.0  rmID_25\n",
       "38  47000.0  rmID_32"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def volume_distri(manifest: pd.DataFrame, rm_ID_num: int):\n",
    "    volume_stat = []\n",
    "    for i in range(1, rm_ID_num + 1):\n",
    "        volume_rmID = manifest[manifest[\"roomID\"] == \"rmID_\" + str(i)].iloc[0]\n",
    "        volume_stat.append(\n",
    "            [\n",
    "                torch.tensor(ast.literal_eval(volume_rmID[\"volume\"]))\n",
    "                .prod()\n",
    "                .round(decimals=0)\n",
    "                .tolist(),\n",
    "                volume_rmID[\"roomID\"],\n",
    "            ]\n",
    "        )\n",
    "    volume_stat = pd.DataFrame(volume_stat, columns=[\"volume\", \"roomID\"])\n",
    "\n",
    "    return volume_stat.sort_values(\"volume\", ignore_index=True)\n",
    "\n",
    "\n",
    "volume_stat = volume_distri(rir_manifest_ID_sum, 39)\n",
    "volume_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this investigation, we determine to augment the data of which volume based on segmented levels of volume to obtain more nutural distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_downsample(manifest: pd.DataFrame, N: int):\n",
    "    \"\"\"\n",
    "    downsample the manifest\n",
    "    \"\"\"\n",
    "    N = int(N)\n",
    "    manifest_downsample = manifest.sample(n=N, random_state=2036)\n",
    "    return manifest_downsample\n",
    "\n",
    "\n",
    "def data_upsample(manifest: pd.DataFrame, N: int):\n",
    "    \"\"\"\n",
    "    upsample the manifest\n",
    "    \"\"\"\n",
    "    N = int(N)\n",
    "    repeated_times = N // len(manifest)\n",
    "    manifest_upsample = pd.concat([manifest] * repeated_times, ignore_index=True)\n",
    "    manifest_upsample = pd.concat(\n",
    "        [\n",
    "            manifest_upsample,\n",
    "            manifest.sample(n=N - len(manifest_upsample), random_state=2036),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    return manifest_upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We processed the data augmentation to make the data better fitted for normal distribution. With regard to volume within 400, we do not do any additional data agumentation, for volume in 400 and 7000, we do additional data augmentation by 2 times. For volume in 7000 and 10000, we do additional data augmentation by 4 times.\n",
    "\n",
    "We assume that the volume beyond 10000 is rare for daily life usage. \n",
    "\n",
    "By using aforementioned data augmentation strategy, we make the whole data follow the normal distribution more and more naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_manifest_ID_resampled = pd.DataFrame(\n",
    "    columns=[\"RIR\", \"roomID\", \"Th\", \"Tt\", \"volume\", \"distRcv\", \"oriSrc\"]\n",
    ")\n",
    "\n",
    "N = 560 + random.randint(-20, 20)\n",
    "for id in range(1, 40):\n",
    "    rir_manifest_id_num = rir_manifest[rir_manifest[\"roomID\"] == \"rmID_\" + str(id)]\n",
    "    rir_volume = (\n",
    "        rir_manifest_id_num[\"volume\"]\n",
    "        .apply(\n",
    "            lambda x: torch.tensor(ast.literal_eval(x)).prod().round(decimals=0).item()\n",
    "        )\n",
    "        .iloc[0]\n",
    "    )\n",
    "    if rir_volume < 400:\n",
    "        if (\n",
    "            len(rir_manifest_id_num) > N\n",
    "        ):  # downsample without additional data augmentation\n",
    "            rir_manifest_id = data_downsample(rir_manifest_id_num, N)\n",
    "            rir_manifest_ID_resampled = pd.concat(\n",
    "                [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        elif (\n",
    "            len(rir_manifest_id_num) < N\n",
    "        ):  # upsample without additional data augmentation\n",
    "            rir_manifest_id = data_upsample(rir_manifest_id_num, N)\n",
    "            rir_manifest_ID_resampled = pd.concat(\n",
    "                [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "    elif rir_volume >= 400 and rir_volume < 7000:\n",
    "        if (\n",
    "            len(rir_manifest_id_num) > N * 3.5\n",
    "        ):  # downsample with additional data augmentation by 2 times\n",
    "            rir_manifest_id = data_downsample(rir_manifest_id_num, N * 3.5)\n",
    "            rir_manifest_ID_resampled = pd.concat(\n",
    "                [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        elif (\n",
    "            len(rir_manifest_id_num) < N * 3.5\n",
    "        ):  # upsample with additional data augmentation by 2 times\n",
    "            rir_manifest_id = data_upsample(rir_manifest_id_num, N * 3.5)\n",
    "            rir_manifest_ID_resampled = pd.concat(\n",
    "                [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "    elif rir_volume >= 7000 and rir_volume < 10000:\n",
    "        if (\n",
    "            len(rir_manifest_id_num) > N * 4\n",
    "        ):  # downsample with additional data augmentation by 4 times\n",
    "            rir_manifest_id = data_downsample(rir_manifest_id_num, N * 4)\n",
    "            rir_manifest_ID_resampled = pd.concat(\n",
    "                [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        elif (\n",
    "            len(rir_manifest_id_num) < N * 4\n",
    "        ):  # upsample with additional data augmentation by 4 times\n",
    "            rir_manifest_id = data_upsample(rir_manifest_id_num, N * 4)\n",
    "            rir_manifest_ID_resampled = pd.concat(\n",
    "                [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "    # # if needed, add more data augmentation for rarer cases\n",
    "    # elif rir_volume >= 10000 and rir_volume < 20000:\n",
    "    #     if (\n",
    "    #         len(rir_manifest_id_num) > N * 6\n",
    "    #     ):  # downsample with additional data augmentation by 4 times\n",
    "    #         rir_manifest_id = data_downsample(rir_manifest_id_num, N * 6)\n",
    "    #         rir_manifest_ID_resampled = pd.concat(\n",
    "    #             [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "    #             ignore_index=True,\n",
    "    #         )\n",
    "    #     elif (\n",
    "    #         len(rir_manifest_id_num) < N * 6\n",
    "    #     ):  # upsample with additional data augmentation by 2.5 times\n",
    "    #         rir_manifest_id = data_upsample(rir_manifest_id_num, N * 6)\n",
    "    #         rir_manifest_ID_resampled = pd.concat(\n",
    "    #             [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "    #             ignore_index=True,\n",
    "    #         )\n",
    "    # elif rir_volume >= 20000:\n",
    "    #     if (\n",
    "    #         len(rir_manifest_id_num) > N * 4\n",
    "    #     ):  # downsample with additional data augmentation by 2.5 times\n",
    "    #         rir_manifest_id = data_downsample(rir_manifest_id_num, N * 4)\n",
    "    #         rir_manifest_ID_resampled = pd.concat(\n",
    "    #             [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "    #             ignore_index=True,\n",
    "    #         )\n",
    "    #     elif (\n",
    "    #         len(rir_manifest_id_num) < N * 4\n",
    "    #     ):  # upsample with additional data augmentation by 2.5 times\n",
    "    #         rir_manifest_id = data_upsample(rir_manifest_id_num, N * 4)\n",
    "    #         rir_manifest_ID_resampled = pd.concat(\n",
    "    #             [rir_manifest_ID_resampled, rir_manifest_id],\n",
    "    #             ignore_index=True,\n",
    "    #         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_manifest_ID_resampled.to_csv(\n",
    "    \"./data/RIR_aggregated/RIR.metadata/RIRLabelAugment.csv\",\n",
    "    index=False,\n",
    ")  # save the resampled manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_manifest_ID_resampled = pd.read_csv(\n",
    "    \"./data/RIR_aggregated/RIR.metadata/RIRLabelAugmentV2.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of the rir dataset manifest for seaborn plotting\n",
    "rir_manifest = rir_manifest_ID_resampled\n",
    "# obtain RIR from which dataset\n",
    "rir_manifest[\"RIR\"] = rir_manifest[\"RIR\"].apply(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "sns.histplot(\n",
    "    x=rir_manifest[\"volume\"].apply(\n",
    "        lambda x: torch.tensor(ast.literal_eval(x)).prod().round(decimals=0).item()\n",
    "    ),\n",
    "    hue=rir_manifest[\"RIR\"],\n",
    "    multiple=\"stack\",\n",
    "    bins=50,\n",
    ")\n",
    "ax.set_xlabel(\"Volume [m$^3$]\", fontsize=16, fontname=\"serif\")\n",
    "ax.set_ylabel(\"Number of RIRs\", fontsize=16, fontname=\"serif\")\n",
    "fig.savefig(\n",
    "    \"./data/Figure/hist_volume.pdf\",\n",
    "    format=\"pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = rir_manifest[\"volume\"].apply(\n",
    "    lambda x: torch.tensor(ast.literal_eval(x)).prod().round(decimals=0).item()\n",
    ")\n",
    "volume_log10 = torch.log10(torch.tensor(volume))\n",
    "volume_unitary_norm = unitary_norm(volume_log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "sns.histplot(\n",
    "    x=volume_log10,\n",
    "    hue=rir_manifest[\"RIR\"],\n",
    "    multiple=\"stack\",\n",
    "    bins=50,\n",
    ")\n",
    "ax.set_xlabel(\"log$_{10}$(Volume) [m$^3$]\", fontname=\"serif\", fontsize=15)\n",
    "ax.set_ylabel(\"Number of RIRs\", fontname=\"serif\", fontsize=15)\n",
    "fig.savefig(\n",
    "    \"./data/Figure/hist_logVolume.pdf\",\n",
    "    format=\"pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bound of the volume is:  3.9542\n",
      "The lower bound of the volume is:  1.5051\n"
     ]
    }
   ],
   "source": [
    "print(\"The upper bound of the volume is: \", round(volume_log10.max().item(), 4))\n",
    "print(\"The lower bound of the volume is: \", round(volume_log10.min().item(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial distance of source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distSrc = torch.tensor(rir_manifest[\"distRcv\"])\n",
    "distSrc_norm = unitary_norm(distSrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "hist_D = sns.histplot(\n",
    "    x=rir_manifest[\"distRcv\"],\n",
    "    hue=rir_manifest_ID_resampled[\"RIR\"],\n",
    "    multiple=\"stack\",\n",
    "    bins=60,\n",
    ")\n",
    "ax.set_xlabel(\"Distance of source [m]\", fontname=\"serif\", fontsize=15)\n",
    "ax.set_ylabel(\"Number of RIRs\", fontname=\"serif\", fontsize=15)\n",
    "fig.savefig(\n",
    "    \"./data/Figure/hist_distSrc.pdf\",\n",
    "    format=\"pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial distance of source estimation results as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bound of the distance is:  28.35\n",
      "The lower bound of the distance is:  0.191\n"
     ]
    }
   ],
   "source": [
    "print(\"The upper bound of the distance is: \", round(distSrc.max().item(), 4))\n",
    "print(\"The lower bound of the distance is: \", round(distSrc.min().item(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ti parameter of sparse stochastic impulse response (SSIR) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Th = torch.tensor(rir_manifest[\"Th\"])\n",
    "Th_unitary_norm = unitary_norm(Th).round(decimals=4).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ti estimation results as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bound of Ti is:  0.276\n",
      "The lower bound of Ti is:  0.005\n",
      "The mean of Ti is:  0.0399\n"
     ]
    }
   ],
   "source": [
    "Ti = torch.tensor(rir_manifest[\"Th\"])\n",
    "print(\"The upper bound of Ti is: \", round(Ti.max().item(), 4))\n",
    "print(\"The lower bound of Ti is: \", round(Ti.min().item(), 4))\n",
    "print(\"The mean of Ti is: \", round(Ti.mean().item(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Td parameter of sparse stochastic impulse response (SSIR) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tt = torch.tensor(rir_manifest[\"Tt\"])\n",
    "Tt_unitary_norm = unitary_norm(Tt).round(decimals=4).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "sns.histplot(x=rir_manifest[\"Tt\"], hue=rir_manifest[\"RIR\"], multiple=\"stack\", bins=60)\n",
    "ax.set_xlabel(\"T60 [s]\", fontname=\"serif\", fontsize=15)\n",
    "ax.set_ylabel(\"Number of RIRs\", fontname=\"serif\", fontsize=15)\n",
    "fig.savefig(\n",
    "    \"./data/Figure/hist_T60.pdf\",\n",
    "    format=\"pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bound of Td is:  7.958\n",
      "The lower bound of Td is:  0.188\n",
      "The mean of Td is:  1.73133\n"
     ]
    }
   ],
   "source": [
    "Td = torch.tensor(rir_manifest[\"T60\"])\n",
    "print(\"The upper bound of T60 is: \", round(Td.max().item(), 5))\n",
    "print(\"The lower bound of T60 is: \", round(Td.min().item(), 5))\n",
    "print(\"The mean of T60 is: \", round(Td.mean().item(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_manifest_ID_resampled.to_csv(\n",
    "    \"~/workspace/acoustic/data/RIR_aggregated/RIR.metadata/RIRLabelAugmentV2.csv\",\n",
    "    index=False,\n",
    ")  # save the resampled manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly sample the speech signals from LibriSpeech dataset to match the count of the RIRs to synthsize the noisy reverberant speech signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LibriSpeech\n",
    "\n",
    "root_path = \"./data/LibriSpeech/train-clean-360\"\n",
    "librispeech_folder = Path(root_path)\n",
    "extension = \".flac\"\n",
    "matching_files = librispeech_folder.rglob(f\"*{extension}\")\n",
    "matching_files = [str(x) for x in matching_files]\n",
    "\n",
    "\n",
    "def audio_len_calc(matching_file: list):\n",
    "    audio, fs = torchaudio.load(matching_file)\n",
    "    length = audio.shape[-1]\n",
    "    return matching_file, length\n",
    "\n",
    "\n",
    "threads = []\n",
    "with ThreadPoolExecutor(os.cpu_count() - 1) as executor:\n",
    "    for i in range(0, len(matching_files)):\n",
    "        threads.append(executor.submit(audio_len_calc, matching_files[i]))\n",
    "librispeech_info = [t.result() for t in threads]\n",
    "librispeech_info = pd.DataFrame(librispeech_info, columns=[\"filename\", \"length\"])\n",
    "librispeech_info.to_csv(\n",
    "    \"./data/LibriSpeech/LibriSpeech_label.csv\",\n",
    "    index=False,\n",
    ")  # save the librispeech manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librispeech_info = pd.read_csv(\"./data/LibriSpeech/LibriSpeech_label.csv\")\n",
    "audio_len = librispeech_info[\"length\"]\n",
    "plt.hist(audio_len, bins=30, color=\"tomato\", ec=\"black\")\n",
    "print(len(audio_len[(audio_len > 200528) & (audio_len < 269336)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this investigation, we decide to use the sequence length between 200528 and 269336 to convolve RIR to augment data since this is the most common length of speech in LibriSpeech dataset.\n",
    "For synthesized mixed speech, we select the speech below 20s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation For RIR estimation\n",
    "def audio_len_calc(matching_files: list):\n",
    "    audio, fs = torchaudio.load(matching_files)\n",
    "    length = audio.shape[-1]\n",
    "    if length > 200528 and length < 269336:\n",
    "        return matching_files, length\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=os.cpu_count() - 1) as executor:\n",
    "    threads = []\n",
    "    for file in matching_files:\n",
    "        threads.append(executor.submit(audio_len_calc, file))\n",
    "audio_info = [t.result() for t in threads]\n",
    "\n",
    "audio_info = [x for x in audio_info if x is not None]\n",
    "audio_long_manifest = pd.DataFrame(audio_info, columns=[\"filename\", \"audioLength\"])\n",
    "audio_long_manifest.to_csv(\"./data/LibriSpeech/audio_long_manifest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration of the mixed speech and its frame-level label\n",
    "\n",
    "reverb_mixed_speech_manifest = pd.read_csv(\n",
    "    \"./data/mixed_speech/reverb_mixed_speech_manifest.csv\"\n",
    ")\n",
    "mixed_speech, fs = torchaudio.load(\n",
    "    os.path.join(\n",
    "        os.getcwd(),\n",
    "        \"data/mixed_speech/mixed_speech.data/reverb_mixed\",\n",
    "        reverb_mixed_speech_manifest[\"mixed_speech\"][2011],\n",
    "    )\n",
    ")\n",
    "mixed_speech_label = torch.load(\n",
    "    os.path.join(\n",
    "        os.getcwd(),\n",
    "        \"data/mixed_speech/mixed_speech_label.data\",\n",
    "        reverb_mixed_speech_manifest[\"mixed_speech_label\"][2011],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration of the mixed speech and its frame-level label\n",
    "t = torch.arange(0, mixed_speech.shape[-1]) / fs\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, mixed_speech.reshape(-1), color=\"cornflowerblue\")\n",
    "plt.ylabel(\"Amplitude\", fontsize=16, fontname=\"serif\")\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t, mixed_speech_label.reshape(-1), color=\"orange\")\n",
    "plt.xlabel(\"Time [s]\", fontsize=16, fontname=\"serif\")\n",
    "plt.ylabel(\"Occupancy level\", fontsize=16, fontname=\"serif\")\n",
    "plt.savefig(\n",
    "    \"./data/Figure/mixed_speech_illustration.pdf\",\n",
    "    format=\"pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed speech synthesis\n",
    "from scripts import synthesize_speech_noise\n",
    "\n",
    "synthesize_speech_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverb speech synthesis\n",
    "from scripts import synthesize_rir_speech\n",
    "\n",
    "synthesize_rir_speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_speech_downsampled_label_path = (\n",
    "    \"./data/mixed_speech/mixed_speech_downsampled_label.data\"\n",
    ")\n",
    "\n",
    "mixed_speech_downsampled_label_lst = os.listdir(mixed_speech_downsampled_label_path)\n",
    "mixed_speech_downsampled_label_lst.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = random.sample(mixed_speech_downsampled_label_lst, 4000)\n",
    "test_one_sample = torch.load(\n",
    "    os.path.join(mixed_speech_downsampled_label_path, test_label[2000])\n",
    ").float()\n",
    "test_one_sample.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_speech_num_occ = torch.tensor([])\n",
    "for i in range(0, len(mixed_speech_downsampled_label_lst)):\n",
    "    mixed_speech_num = torch.load(\n",
    "        os.path.join(\n",
    "            mixed_speech_downsampled_label_path, mixed_speech_downsampled_label_lst[i]\n",
    "        )\n",
    "    ).float()\n",
    "    mixed_speech_num_occ = torch.cat([mixed_speech_num_occ, mixed_speech_num], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------ Split train， val， and test ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_clean_manifest_path = \"./data/noiseReverbSpeech\"\n",
    "\n",
    "val_size = test_size = 2000\n",
    "\n",
    "noisyCleanPair = pd.read_csv(\n",
    "    os.path.join(noisy_clean_manifest_path, \"reverbSpeech.metadata.csv\")\n",
    ")\n",
    "\n",
    "train_manifest, test_manifest = ms.train_test_split(\n",
    "    noisyCleanPair,\n",
    "    train_size=len(noisyCleanPair) - test_size,\n",
    "    test_size=test_size,\n",
    "    random_state=2036,\n",
    ")\n",
    "\n",
    "train_manifest, val_manifest = ms.train_test_split(\n",
    "    train_manifest,\n",
    "    train_size=len(train_manifest) - val_size,\n",
    "    test_size=val_size,\n",
    "    random_state=2036,\n",
    ")\n",
    "\n",
    "\n",
    "# shuffle\n",
    "train_manifest = train_manifest.sample(frac=1, random_state=2036).reset_index(drop=True)\n",
    "val_manifest = val_manifest.sample(frac=1, random_state=2036).reset_index(drop=True)\n",
    "test_manifest = test_manifest.sample(frac=1, random_state=2036).reset_index(drop=True)\n",
    "\n",
    "manifest_path = \"./data/noiseReverbSpeech\"\n",
    "if not os.path.exists(manifest_path):\n",
    "    os.makedirs(manifest_path)\n",
    "train_manifest.to_csv(os.path.join(manifest_path, \"train_manifest.csv\"), index=False)\n",
    "val_manifest.to_csv(os.path.join(manifest_path, \"val_manifest.csv\"), index=False)\n",
    "test_manifest.to_csv(os.path.join(manifest_path, \"test_manifest.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_manifest = pd.read_csv(\"./data/noiseReverbSpeech/train_manifest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the azimuth and elevation to the reverb speech manifest\n",
    "train_manifest_reverb = pd.read_csv(\"./data/noiseReverbSpeech/train_manifest.csv\")\n",
    "val_manifest_reverb = pd.read_csv(\"./data/noiseReverbSpeech/val_manifest.csv\")\n",
    "test_manifest_reverb = pd.read_csv(\"./data/noiseReverbSpeech/test_manifest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_speech_manifest_path = \"./data/Database/mixed_speech\"\n",
    "\n",
    "mixed_clean_manifest = pd.read_csv(\n",
    "    os.path.join(mixed_speech_manifest_path, \"mixed_speech_manifest.csv\")\n",
    ")\n",
    "\n",
    "mixed_reverb_manifest = pd.read_csv(\n",
    "    os.path.join(mixed_speech_manifest_path, \"reverb_mixed_speech_manifest.csv\")\n",
    ")\n",
    "\n",
    "# add numOcc info to mixed_clean_manifest\n",
    "num_occ = mixed_reverb_manifest[\"numOcc\"]\n",
    "mixed_clean_manifest.insert(2, \"numOcc\", num_occ)\n",
    "# remove rir_info from mixed_clean_manifest\n",
    "mixed_reverb_manifest = mixed_reverb_manifest.drop(columns=[\"rir_info\"])\n",
    "\n",
    "mixed_clean_manifest.to_csv(\n",
    "    os.path.join(mixed_speech_manifest_path, \"mixed_speech_manifest.csv\"), index=False\n",
    ")\n",
    "mixed_reverb_manifest.to_csv(\n",
    "    os.path.join(mixed_speech_manifest_path, \"reverb_mixed_speech_manifest.csv\"),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------- Split train, val and test dataset for mixed_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_speech_manifest_path = \"./data/mixed_speech_noise\"\n",
    "\n",
    "val_size = test_size = 2000\n",
    "\n",
    "reverb_mixed_speech_manifest = pd.read_csv(\n",
    "    os.path.join(mixed_speech_manifest_path, \"mixed_speech_manifest.csv\")\n",
    ")\n",
    "\n",
    "train_manifest, test_manifest = ms.train_test_split(\n",
    "    reverb_mixed_speech_manifest,\n",
    "    train_size=len(reverb_mixed_speech_manifest) - test_size,\n",
    "    test_size=test_size,\n",
    "    random_state=2036,\n",
    ")\n",
    "\n",
    "train_manifest, val_manifest = ms.train_test_split(\n",
    "    train_manifest,\n",
    "    train_size=len(train_manifest) - val_size,\n",
    "    test_size=val_size,\n",
    "    random_state=2036,\n",
    ")\n",
    "\n",
    "\n",
    "# shuffle\n",
    "train_manifest = train_manifest.sample(frac=1, random_state=2036).reset_index(drop=True)\n",
    "val_manifest = val_manifest.sample(frac=1, random_state=2036).reset_index(drop=True)\n",
    "test_manifest = test_manifest.sample(frac=1, random_state=2036).reset_index(drop=True)\n",
    "\n",
    "manifest_path = \"./data/mixed_speech_noise\"\n",
    "if not os.path.exists(manifest_path):\n",
    "    os.makedirs(manifest_path)\n",
    "train_manifest.to_csv(os.path.join(manifest_path, \"train_manifest.csv\"), index=False)\n",
    "val_manifest.to_csv(os.path.join(manifest_path, \"val_manifest.csv\"), index=False)\n",
    "test_manifest.to_csv(os.path.join(manifest_path, \"test_manifest.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_speech_manifest_path = \"./data/mixed_speech_noise\"\n",
    "\n",
    "val_size = test_size = 2000\n",
    "\n",
    "reverb_mixed_speech_manifest = pd.read_csv(\n",
    "    os.path.join(mixed_speech_manifest_path, \"mixed_speech_manifest.csv\")\n",
    ")\n",
    "\n",
    "train_manifest, test_manifest = ms.train_test_split(\n",
    "    reverb_mixed_speech_manifest,\n",
    "    train_size=len(reverb_mixed_speech_manifest) - test_size,\n",
    "    test_size=test_size,\n",
    "    random_state=2036,\n",
    ")\n",
    "\n",
    "train_manifest, val_manifest = ms.train_test_split(\n",
    "    train_manifest,\n",
    "    train_size=len(train_manifest) - val_size,\n",
    "    test_size=val_size,\n",
    "    random_state=2036,\n",
    ")\n",
    "\n",
    "\n",
    "# shuffle\n",
    "train_manifest = train_manifest.sample(frac=1, random_state=2036).reset_index(drop=True)\n",
    "val_manifest = val_manifest.sample(frac=1, random_state=2036).reset_index(drop=True)\n",
    "test_manifest = test_manifest.sample(frac=1, random_state=2036).reset_index(drop=True)\n",
    "\n",
    "manifest_path = \"./data/mixed_speech_noise\"\n",
    "if not os.path.exists(manifest_path):\n",
    "    os.makedirs(manifest_path)\n",
    "train_manifest.to_csv(os.path.join(manifest_path, \"train_manifest.csv\"), index=False)\n",
    "val_manifest.to_csv(os.path.join(manifest_path, \"val_manifest.csv\"), index=False)\n",
    "test_manifest.to_csv(os.path.join(manifest_path, \"test_manifest.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acoustic-toolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
